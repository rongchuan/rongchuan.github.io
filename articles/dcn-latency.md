## 数据中心网络传输时延优化

随着互联网行业的井喷式发展，IDC成为公司基础设施建设越来越重要的一环。机房建设可不是一件容易的事情，通常需要考虑这几个方面：

>* 兼顾成本和性能(买个菜还要讲性价比呢)；
>* 可扩展性，这点非常重要，电商活动的时候加机器非常频繁，而网络拓扑结构的优劣对可扩展性起了决定性的作用；
>* 容错性，物理机规模达到上万以后，硬件故障是常态，因此硬件容错比如磁盘热插拔就变得非常重要；
>* 节能，比如电压不太稳定但成本低且环保的绿色能源和电压稳定的电网电能的配比；

![屏幕快照 2017-08-27 下午10.11.41.png](http://ata2-img.cn-hangzhou.img-pub.aliyun-inc.com/2c1043e929628f05fd2eb5654aacf2ed.png)

上图是TOP500 高性能计算系统使用的网络架构，可以看到10年千兆以太网和Infiniband几乎平分天下，借助RDMA和zero copy、kernal bypass等技术带来的低时延、对操作系统、cpu的低消耗，近几年Infiniband占据的份额也是水涨船高，不过独立的硬件同时也带来更高的成本。

从兼顾成本和性能的角度来看，以太网 + TCP/IP协议栈无疑是更好的选择，这也是目前大多数数据中心采用的方案。然而TCP/IP作为一种广泛使用于各类网络的协议，用于特定的数据中心网络时需要一些针对性的优化才行，下面从时延的角度看看如何优化。

#### 时延问题背景

虽然数据中心网络的三层交换拓扑给服务器提供了高带宽和路径多样性，但是并没有彻底将数据中心网络传输时延控制在一个较低水平。2009年google、amazon等巨头的集体[发声](http://highscalability.com/blog/2009/7/25/latency-is-everywhere-and-it-costs-you-sales-how-to-crush-it.html)将问题的重点转移到了传输时延上，Amazon的一份报告显示，网页打开速度每增加100ms，销售额就会下降1%。

![屏幕快照 2017-09-03 上午11.29.18.png](http://ata2-img.cn-hangzhou.img-pub.aliyun-inc.com/7f06847846c2260abd541036d22293a3.png)


这句话套在同样作为电商平台的淘宝身上应该同样有效。当然，一个商品详情页的打开速度依赖于多方面的因素，优化前端代码和部署，优化mtop接口响应速度都能有效减少网页打开时延，那么从网络方面入手有哪些优化手段呢？

#### 网络水位与时延

计算能力不足，买服务器扩展计算能力就可以了，但是买带宽却无法相应地减少传输时延。

为什么单纯的提高带宽仍然无法做到低时延？

网络研究者习惯把整个网络当成一个大的交换机，终端服务器通过NIC往网络里灌数据，我们把网络设备控制哪些包应该转发，哪些应该丢弃的过程叫做flow control。flow这个词很形象，把整个DCN想象成一个水管，如下。

![屏幕快照 2017-09-03 上午11.27.10.png](http://ata2-img.cn-hangzhou.img-pub.aliyun-inc.com/d34e6a782cf54e37ec9fa0949a80ffa6.png)

假设当前网络水位为位置1，达到线速时为位置2，水位继续上涨，开始出现排队，位置3表示队列被塞满。显然位置2是最佳的，带宽得到充分利用而且没有任何包在排队。一味增加带宽也就是管道的宽度固然可以容许终端以更快的速度发包，可是如果不能很好地处理排队问题，便无法做到低时延。

Flow control从宏观上看就是一个反馈控制系统，通过网络节点发反馈和终端的配合达到最优化传输时延的目的。要维持流量水位在位置2的水平，那么当流量水位高于位置2的时候，我们应该向包的来源发送负反馈，使其降低发包的速率，减轻网络的水位；当流量低于位置2的时候，应该向来源发送正反馈，提升发包速率，增加带宽利用率。根据反馈信号作用的来源不同，通常我们将流控分为两类，端到端流控(调控终端传输速率)以及点到点流控(调整网络节点速率，通常指交换机)。

#### 端到端流控优化

为了获得网络转发的高性能，交换机通常是由纯硬件逻辑构成的，因此交换机只保留了非常简单的功能，如转发、丢包等，这样的话网络设备能够保证最好的性能。所以即便交换机是第一个知道排队事件发生的地方，但反馈信息并不是由交换机直接发送给终端的，相反，探知排队事件的任务交给拥有丰富软件库的终端来做。TCP/IP协议就被设计成一套复杂的发送 -- 确认回路，不断地探测当前网络的状况。

但是网络设备和终端相隔遥远，队列长度对于终端来说不是一个容易知道的事情，最早的Reno版本的TCP通过丢包的事件来探测网络的拥堵情况，而丢包又是通过一段时间(通常是200ms)超时之后没有收到ACK来确认的。当有丢包事件被探测到，终端就会进入我们熟知的快重传阶段，发送窗口减半，之后每轮加1。

##### RTO优化

TCP Reno流控过程搬到数据中心网络场景里来，有几个点明显可以优化，比如200ms的RTO(超时重传时间)是依据广域网的平均RTT来设置的，数据中心网络作为高速局域网，RTT相比外网要低好几级，通常在100us左右(可以在两台同机房机器之间ping获得)，这种设置对于时延要求较高的场景而言其实会有影响，因为一旦有网络丢包，服务质量就下去了。《Safe and effective fine-grained tcp retransmissions for datacenter communication》给出的建议是，RTO一般设置为RTT的探测均值加上其4倍线性偏差(对应到集团生产网大概设为200us左右)，不过它的实验有一个很有趣的结论，就是RTO从200ms降到1ms的时候，传输时延有很大优化，但是从1ms降到200us的时候变化不大。

##### 探测拥塞算法优化

另外，难道我们非得等超时才能知道网络拥堵了吗？有没有更好的办法？TCP Vegas版本设计了一个更复杂的终端探测网络拥塞的算法。事实上，在丢包之前，网络包会经历一个排队的过程，经历排队的这一轮传输所花费的时间显然会比上一轮没有经历排队的高，因此Vegas通过维护每轮传输时间的差异率来探测网络拥堵，当RTT变化斜率超过一定值，终端就会进入快重传阶段。显然，Vegas版本的TCP和Reno版本共存时，Vegas能更快地发现拥塞，同时也能更早地恢复传输，所以Vegas会抢占Reno的带宽，带宽公平的问题使得Vegas并没有被广泛推广，这也是为什么TCP被研究这么多年，真正应用的版本(reno、newreno、sack、vegas、cubic)屈指可数的缘故。

##### 网络设备上的优化

除了公平性的问题，TCP升级版本之所以困难的另一个原因，终端的控制权不在网络供应商手里，但是如果我们在交换机上动手脚，这些问题就不存在了。让我们再次回忆一下网络拥塞时整个传输回路的过程，队列满了，后来的包被丢弃，接收端没有收到包所以不会发送ack，发送端没有收到ack然后等待超时，于是触发快重传。等等，为什么一定要到队列满了才丢包呢？队列长度到达一定值的时候就开始丢的话，终端不就可以更快的收到网络拥塞的信号进而放慢发包速度吗？RED(random early droped)就是这么做的，为了保证丢包的公平性，RED引入了一个丢包概率值p，这个值随着队列长度的增加而增加，这样的话，那些流量很大的连接有较多的包被丢弃，速率回退幅度相比流量小的连接更大，因而保证了带宽竞争的公平性。

再次回到上文讲Vegas提出的问题，难道一定要等超时才能知道拥塞了吗？事实上，超时跟丢包并没有直接的关系，通过超时来断定丢包其实是一种隐晦的推测，这种判断丢包的方式一方面等待的时间长，另一方面不是100%正确的，有可能一个数据包经过每一个交换机都排了队导致超过RTO后ack没有及时发回，但实际上已经到达接收端了，在隐式判断丢包的方法中，误判无法避免。但是丢包这件事情，把包丢弃的交换机是第一个知道的，有没有办法让交换机直截了当地、显式地把这个信息通知到发送端呢？随着交换机计算能力的提上，ECN(Explicit Congestion Notification)成为可能，交换机通过置TCP包的特定位(ECE)来告知终端网络拥塞，然后终端得到明确的拥塞信号，进入快重传阶段。同样出于公平性的考虑，ECN借鉴了RED的丢包概率理念，将RED的按概率丢包行为改成按概率置位，这样一来，不丢包也可以及时发现网络拥塞，从而更快的让网络从排队中恢复过来。具体过程参见下图。

![test.gif](http://ata2-img.cn-hangzhou.img-pub.aliyun-inc.com/152a5c8c6a509caf7ef7168c694c4281.gif)

##### DCTCP

流控发展到ECN，整个拥塞控制的思路发生了一个很大的转变。以前丢包代表网络拥堵，所以当我们说拥塞的时候，网络的情况已经很糟糕了，因此需要大幅度削减发送窗口，没毛病。可是到了ECN这，有可能队列长度刚开始增长，接收端就知道了于是开始窗口减半，也有可能队列真的已经满了，接收端开始减半。这个问题在广域网上还不太明显，RTT比较大因此反应时间没那么快，可是到了RTT是100us级别的数据中心里面，基本上队列长度常年维持在一个较低的水平，可是相应的带宽利用率也跟着下去了。究其原因，终端对拥塞没有程度的概念，在队列长度很短，`拥塞程度`不高的时候依然将窗口减半就显得反应过度了。DCTCP做的很漂亮的工作就是把拥塞程度的概念引进来，不改变ECN的机制，而是在快重传的地方改了几十行代码，将一见到拥塞标志就窗口减半的机制改为，统计当前窗口中被标记拥塞的包的比例，这个比例代表拥塞程度，发送窗口的回退比例与拥塞程度成正比，以前的减半动作在DCTCP这里成了最坏的情况(拥塞程度100%)。正常情况下，轻度拥塞时，终端依然能够以较高的速率传输，这样的话，在不损失ECN带来的低时延的红利的同时，DCTCP也将带宽利用率维持在一个较高的水准。更形象的说，回到上面的水管图，就是让网络这个水管的水位一直在位置2附近且以尽量小的幅度波动。不得不说，DCTCP真是一个兼顾了低时延和高带宽利用率而且简洁有效的漂亮方案。

##### 针对DCN流量特点的优化方案

当我们谈论数据中心网络时，我们在谈论什么？不是办公网不是城域网也不是骨干网，而是有着自己流量特点的数据中心网络。一份报告《The nature of data center traffic: measurements & analysis》中指出，数据中心网络的流量有着随机突发性增长的特点，而这种突发性流量大都是拜离线任务所赐，比如索引build的MR任务，比如离线训练任务，这些任务天然有聚合式特点，在reduce阶段，所有计算完成的节点会向同一个出口发送数据完成最后的汇总，这个时候就形成了一个多扇入低单扇出的场景。又由于交换机的上下行带宽一致，相当于多个和你一样力量的人同时向你出拳，人越多便伤得越重。通常我们把这种场景成为incast。下图简单描述了这个过程。

![屏幕快照 2017-09-04 上午12.58.32.png](http://ata2-img.cn-hangzhou.img-pub.aliyun-inc.com/58f82baf53c2b84f0fb652b6673675ce.png)

我们可以想象一下最坏的情况，假如ToR的队列长度是10，当有11台服务器同时开始向它发送数据的时候，拥塞策略甚至来不及生效，丢包(如上文所说，严重的拥塞)就已经发生了。针对这种流量特点，清华大学做出了非常漂亮的工作 -- CP《Catch the Whole Lot in an Action: Rapid Precise Packet Loss Notification in Data Centers》，不是couple的CP而是Cut Payload的CP，简单来说，就是当交换机队列长度超过阈值时，交换机会把接下来的包的数据内容剥离掉，只剩下一个包头，这个包继续走到接收端，被识别出是一个网络拥塞的标志，于是得以继续接下来的流控策略。由于包头相比包体通常很小，因此对于突发流量的容忍度很好，因为突发流量不会打断拥塞通知的过程，影响它的流控。严格说起来，这篇文章是纯大陆学术机构首次在网络A级会议上发表，确实很漂亮扎实。不过CP的方案是通过NetFPGA的方式定制的，而且需要终端升级配合，改动相对比较大，如果没有厂商支持，恐怕应用不起来。而ECN已经写进RFC中，有广泛的硬件设备支持。

另外专门针对Incast设计了通信协议的ICTCP可谓是流控协议中的一股清流。别人都是控制发送端的发包速率来达到端到端流控的效果，而ICTCP确是控制接收端的接收窗口来达到流控的目的，可谓独此一家，骨骼清奇，具体就不展开了。

#### 点到点流控优化

当网络拥塞时，交换机永远是第一案发现场。虽然控制终端发送速率的方式经过优化后效果不错，但还是绕了一圈从接收端再返回发送端。在这一轮的过程中如果出现了突发流量呢？那么不可避免的会丢包。而对于一些高性能网络来说，丢包是一件蛮影响性能的事情。那么有没有更快的办法，不绕那么一圈就可以达到控速的目的呢？事实上还真有，IEEE 802.3X标准定义了一种针对以太网数据链路层流控的PAUSE Frame功能，当交换机某个端口的队列超过阈值，该交换机会往上一个交换机节点发送PAUSE Frame，告知它不要再发了，我受不了了。收到暂停帧的交换机暂停自身的发包行为，同时将PAUSE信号再往上一跳发，一级一级最终会反馈到终端，终端也会跟着暂停发送行为，当拥塞的交换机恢复了，它会反馈一个恢复信号帧通知上游可以继续发包。不过这种方式不区分来源，所有上一跳过来的流量都会被暂停，因此虽然能够做到不丢包，但是在暂停阶段网络的带宽利用率显然不会高。

IEEE standard 802.1Qbb标准定义了QCN机制，在PAUSE Frame的基础上加入了优先级队列(Priority-based Flow Control)，通常会有八个优先级，当拥塞发生时，低优先级队列的连接会被优先暂停，其余的可以继续发送，具体参见《Data center transport mechanisms: Congestion control theory and ieee standardization》，目前比较火的RDMA on Ethernet中PFC是依赖的一项重要技术，这可是保证不丢包的神器，如果RDMA可以大规模部署，访问任意一台机器的内存都如探囊取物一般，那么Datacenter as a computer就可以往前走一大步了，不说磁盘、CPU，至少一个数据中心的内存看起来就是一块内存。PFC接下去的优化就大同小异了，DCTCP对ECN的优化同样可以放到QCN上，将终端暂停行为修改为按照拥塞程度调整发送速率。

#### 接下来要做什么(YY)？

##### 在线离线分离

线上偶发的时延抖动，往往查下去不是磁盘读写的问题就是网络流量突增的问题。出于提高机器资源利用率的目的，在线离线混布在相同的物理机上，没有问题，可是在传输的时候，在线和离线应该分开来，因为二者的SLA显然不一样，在线查询服务以查询时延作为衡量服务质量的标准，离线build出来的索引动则几百G，索引的传输以带宽为服务质量标准，没有人会在意离线索引是早几分钟还是晚几分钟生效，而是在意拖索引的时候能够利用尽量多的带宽，这两种SLA并不冲突，因为决定时延的是排队策略，如果排队时在线服务的包先走，离线的后走，那么在线流量的排队时延会降低，而带宽呢？回到上面的管道图，都已经排队了，说明水位已经在位置2之上了，网络链路的带宽已经完全用起来了，此时离线对于带宽的SLA也得到了满足，双赢啊。所以如果按照现在的排队策略，first in first out，当离线任务的包挡在在线任务的包前头，拖慢在线服务的传输时延，在网络层面分离在线离线就很有必要了。事实上，TCP/IP协议在设计之初便考虑到了网络差异化Qos的需求，在IP包头里面专门保留了8位的DiffServ字段。在交换机计算能力日趋强大的今天，我们是否应该考虑在交换机的流控策略中加入基于优先级的调度(也就是往DiffServ字段塞优先级)，优先保证在线服务的传输能力，其次再考虑离线服务的传输？

##### 多协议栈共存时的竞争公平性

我们有了这么好的优化协议，是否在一个新机房全部用新协议就可以了呢？对于公有云机房来说，还是不可以，因为虚拟机用什么样的操作系统，什么版本的TCP协议栈，又一次脱离了我们的控制。脱离控制的后果，就是一旦网络中有优化版本的协议如ECN和旧版本共存时，带宽基本被使用ECN的终端吃完了，如下图。

![屏幕快照 2017-09-04 下午11.30.01.png](http://ata2-img.cn-hangzhou.img-pub.aliyun-inc.com/51d4fc938cd638e97849c8d641267171.png)

好在虚拟机和硬件之间还有一层hypervisor做中转，最典型的，ECN和非ECN共存时，我们可以在hypervisor层修改包头的内容将非ECN流量翻译成ECN，让不同协议栈的终端享受公平竞争带宽的权利，越来越多的服务上云以后，这个问题必将得到重视。

##### 精确速率控制

网络资源常常被人忽视，因为目前来说网络传输能力的增长比计算能力的增长快，网络资源不够用的情况基本上碰不到，但是要做到Datacenter as a computer，网络资源也应该作为可以池子可以分配，而这种能力依靠粗粒度的TCP/IP流控无法实现。

待续。。。
